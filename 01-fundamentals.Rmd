# R Fundamentals {#fundamentals}


## Package Management

### Package Storage

Here is where all the libraries are stored.  
Can you guess which are the **baseR and third party libraries** stored ?  
```{r}
.libPaths()
```

### Package Listing

Use **`installed.packages()`** to return a data frame that list all installed packages.  
```{r}
head( installed.packages() )
```

**TOO MANY COLUMNS !!**  
Below are the column names and its numbering for filtering purpose.  
```{r}
colnames( installed.packages() )
```

**Perform column filter** based on column names as necessary.  
Set parameter **priority = 'NA' to exclude base R** packages.  

```{r}
head( installed.packages( priority='NA' ) [,c(1,3)] )
```

Set parameter **priority = 'high'** will include **ONLY base R** packages  
```{r}
head( installed.packages( priority='high' ) [,c(3,2)] )
```

### Package Install / Removal

```{r eval=FALSE}
install.packages( c('ggplot', 'ggExtra') )
remove.packages ( c('ggplot', 'ggExtra') )
```

### Package Update

```{r eval=FALSE}
old.packages()      ## list all old packages, their old version and available new version
update.packages()             ## need to input y/n/c for each old package to update
update.packages( ask=FALSE )  ## automatically update all packages without asking
```


### Package Corruption

Sometimes a corrupted R package can give below issues:  

- Error loading a library  
- Error installing a library  
- Error removing a library  

The solution is to:  

- Remove the problematic package folder (see where they are stored using **.libPaths()** )  
- Reinstall the package  

## Data Types

### String

#### String Comparison

#### String Manipulations

**Splitting**  
**Combining**  
**Extracting**  


### Dates Manipulation

#### Formatting

#### Dates Comparison

#### Dates Manipulation

**Days Between**  

**First Day of the Month**  

**Last Day of the Month**  

**Days/Months/Years After**  


## Conditioinal Decision

## Loops

### Sample Data
```{r,echo=FALSE}
set.seed(1234)
n=5
my.df = data.frame(
  com  = paste('C',sample(1:2, n, replace = T),sep=''),
  dept = paste('D',sample(1:3, n, replace = T),sep=''),
  grp  = paste('G',sample(1:2, n, replace = T),sep=''),
  team = paste('T',sample(1:2, n, replace = T),sep=''),
  value1 = rnorm(1:n, mean = 50, sd = 5),
  value2 = rnorm(1:n, mean = 20, sd = 3),
  value3 = rnorm(1:n, mean = 10, sd = 1),
  stringsAsFactors = F
)
```

```{r}
my.df
```


### Loop Through A Vector

### Loop Through Multiple Columns/Rows

**`apply`** loops through all rows or columns, take each column/row as a vector and supply them as input to a function. The function will compute the vector supplied, and return output in one of the form below base on the function used:    

- Return **single value** per row/column, eg. `sum()`  
- Return **multiple value** per row/column, eg. `function(x) x^2`  

At the end of the 'loop', all results from each iteration are combined into one vector or matrix as final output.  

> **`apply (X, MARGIN, FUN, ...)`**  
> $\quad$ `X : matrix (anything else will be converted to matrix`  
> $\quad$ `MARGIN: 1 - row-wise, 2-column-wise`  
> $\quad$ `FUN: function to apply, can be a custom function`  
> $\quad$ `... : optional parameters for FUN`  

#### Row-Wise Function

Iterate through each row with parameter `MARGIN=1`.  
**Each output column represent a data ROW**.  

```{r, collapse = TRUE}
# single value returned per row
apply( my.df[,5:7], 1, sum )

# multiple values returned per row
apply( my.df[,5:7], 1, function (x,y) x^y, y=3 )  
```

#### Column-Wise Function

Iterate through each column with paramneter `MARGIN=2`.  
**Each output column represent a data COLUMN**.  

```{r, collapse = TRUE}
# single value returned per column
apply( my.df[,5:7], 2, sum)   

# multiple values returned per column
apply( my.df[,5:7], 2, function (x,y) x^y, y=3 )
```


## Data Import

### Data Import Performance

There are multiple ways to import data into R, most common ones are discussed here:  

- Base **read.table**  
- **data.table::fread**  
- **readr::read_csv**  

#### Comparison

Below comparison charts shows **reading performance relative to data.table::fread**:  

- Base **read.table** is more than 5x slower on large files  
- **readr** performance is acceptable, and improving **closer to fread** at larger data file  

![Fast Data Reading](./images/read_performance.jpg)  
[Source](https://csgillespie.github.io/efficientR/5-3-importing-data.html#fast-data-reading)

### What To Choose

Few criterias must be considered when choosing the right import:  

**Performance**  

- **fread** is very high speed, follow by **readr**  
- **read.table** is slow, and not suitable for large datasets  

**Parsing Detection**  

- **fread** autmatically detect header  
- **fread** autmatically detect column delimeter and decimal  
- **readr** auto parse date/time format if data in format "yyyy-mm-dd"  

**Factor Conversion**  

- **fread** and **read.table** both has **stringAsFactor=TRUE** option for auto conver string to factor  
- In **readr**, need to manually specify which column to convert to factor, and all the factor levels values required definition upfront (downside)  

**Progress Bar**  

- **fread** and **readr** provides progress info when the loading is going to take a while  

**Other Features**  

- **readr** is part of tidyverse ecosystem, readr returns tibble and datafrma eobject  
- **fread** has advance data manipulation functions at high speed, fread return data.table and data.frame object  

### Working Directory

Before importing data into R, we must first check the **current working directory**, so that we can specify the **relative path** for the files we want to import.  

To display the current working directory.  

```{r, collapse=TRUE}
getwd()
```

To set the working directory, use below:  

```{r eval=FALSE}
setwd("...new path...)
```

### Sample Data File

We use sample data from excel, exported to CSV.  
Following importing method shows the process of Excel-->csv-->R data.frame.    

#### Original Excel Data Source

![Check out the Yellow areas in codes below !](./images/sample_excel_import.jpg)

#### Exported CSV File from Excel

```
,,dept,gender,weight,height,date_birth,amount,date_last,date first
1,ID101,D1,Male,35,173,1/7/1973,100,2/29/2016,2013-07-31
2,ID102,D2,Female,37.1,164,28/2/1980,121,4/1/2017,2013-08-31
3,ID103,D3,Female,43.12,178,31/12/1978,152,10/31/2015,2014-12-31
4,ID104,D1,Male,38.123,182,12/1/1997,133,11/1/2016,2015-02-28
5,ID105,D1,Male,54.1234,159,2/1/1982,143,9/30/2016,2012-06-15
6,ID106,D3,Female,34.12345,166,26/7/1973,155,11/27/2015,2013-04-28
7,ID107,D2,Male,49.123456,153,21/8/1985,117,3/31/2017,2014-03-01
8,ID108,D1,Male,50.2,159,2/1/1982,143,9/30/2016,2011-06-15
9,ID109,D3,Female,59.1,166,13/7/1975,155,11/1/2017,2012-04-02
10,ID110,D2,Male,63.2,163,24/8/1982,117,3/12/2016,2013-03-12
11,ID111,D3,Female,75.1,170,9/8/1979,135,2/1/2015,
12,ID112,D2,Male,52.1,169,NULL,128,NA,
13,ID113,D3,NULL,88.8,171,NULL,141,NA,
### Importing CSV
```

### Base::read.csv

**read.csv** is a similar to **read.table** but with some defaults value set as below for convenience of CSV import.  

In the resulting data.frame, row.names attribute are automatically assigned with sequence number starting from 1.  

> **read.csv** ( file,   
> $\quad$ header = TRUE  - contain header row  
> $\quad$ sep = ","  - column seperator marked as ','  
> $\quad$ dec = "."  - decimals marked as '.'  
> $\quad$ na.strings = "NA"  - vectors that define missing data marking <NA>  
> $\quad$ check.names = TRUE - col names with white space replaced with '.'   
> $\quad$ stringsAsFactors = TRUE - convert string to factor  

As an exmple, the import below:  

- Specified multiple string elements that represents  **missing data** in the CSV file  
- Set **stirngsAsFactors=FALSE** so that all string columns are not converted to factor automatically, on other words, they are imported as character  
- **./** is a relative path represents  current R working directory. It can be replaced with complete non-relative path  
- Default parameter **check.names=TRUE** automatically named 'unnamed' column, as well as replacing white spaces for column names with '.'  

```{r}
sample.df <- read.csv ("./datasets/import_sample.csv", 
    stringsAsFactors = FALSE,
    na.strings=c('NA','NULL',''),
    encoding="UTF-8")

sample.df [,-10]
```

```{r, collapse=TRUE}
str(sample.df)
```


### data.table::fread

> **fread** ( input,   
> $\quad$ header = 'auto'  - auto detect header (if all non empty cells in first row character)  
> $\quad$ sep = "auto"  - auto detect column  seperator  
> $\quad$ dec = if (sep!=".") "." else ",", in a way automatic selected  
> $\quad$ na.strings = "NA"  - vectors that define missing data marking <NA>  
> $\quad$ check.names = FALSE - do not replace col names with white space  with '.'   
> $\quad$ stringsAsFactors = FALSE - do not convert string to factor  
> $\quad$ nrows = -1 - how many rows to read, default -1 means read all rows  
> $\quad$ data.table = TRUE - return data.table object, FALSE - return data.frame object  

```{r}
library(data.table)

my.dt = fread("./datasets/import_sample.csv",
    stringsAsFactors = TRUE,
    na.strings=c('NA','NULL',''),
    check.names = TRUE,
    data.table = FALSE)
my.dt[,-10]

str(my.dt)
```

### readr::read_csv

- read_csv returns object type: **‘tbl_df’, ‘tbl’ and 'data.frame'**  

> **read_csv** ( file,   
> $\quad$ col_names = TRUE - first row is header, if FALSE or char vector to specify column names  
> $\quad$ col_types = NULL - all columns type will be imputed based on first 100 rows, alternatively specify:  
> $\quad$ $\quad$ list( Sepal.Length = col_double(), ...) 
> $\quad$ na = c("", "NA") - characters used for detecting missing data <NA>  
> $\quad$ skip = 0 - no skipping for first number of rows  
> $\quad$ n_max = Inf - how many rows to read, default read all  

```{r}
library(readr)

my.rd = read_csv("./datasets/import_sample.csv", 
          na = c('NA','NULL',''),
          col_types = list (
            gender=col_factor(c('Male','Female'))
          ))

my.rd[,-10]

str(my.rd)
```
