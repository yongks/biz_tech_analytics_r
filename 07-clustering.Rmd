# Clustering

## Introduction

- Cluster analysis is a data-reduction technique designed to uncover subgroups of observations within a dataset. 
- It reduce a large number of observations to a much smaller number of clusters or types.  
- A cluster is defined as a group of observations that are more similar to each other than they are to the observations in other groups. 

## Application
- **Business** : researchers use cluster analysis for customer segmentation. Customers are arranged into clusters based on the similarity of their demographics and buying behaviours. Marketing campaings are then tailored to appeal to the groups.  
  
- **Psychological**: researchers cluster data on the symptoms and demographics of depressed patients, seeking to uncover subtypes of depression, with the hope of finding more effective targeted treatments and a better understanding of the disorder.
  
- **Medical**: researchers use cluster analysis to help catalog gene-expression patterns obtained from DNA microarray data. This can help them to understand normal growth and development and the underlying causes of many human diseases

- **Information Retrieval**: The world wide web consists of billions of Web pages, and the results of a query to a search engine can return thousands of pages. Clustering can be used to group these search results into a small number of clusters, each of which captures a particular aspect of the query. For example, a query of "movie" might return Web pages grouped into categories such as reviews, trailers, starts and theaters. Each category (Cluster) can be bnorken into subcategories (sub-clusters), producing a hierachical structure that further assists a user's exploration of the query results.


## General Steps in Cluster Analysis

1. **Choose appropriate attributes**  
    + This is the most important steps. 
    + Choose attributes that that actions can be taken upon
    + A sohisticated cluster analysis can't compensate for a poor choice of variables  <br><br>

2. **Scale Data**  
    * If variables vary in range, then the variable with the largest value will have the greatest impact on result. This is undesirable.
    * Therefore data must be scaled so that they can be compared fairly
    * Popular scaling methods are:
        + Normalize to mean=0 and sd=1
        + Divide by Max
        + Minus min, divide by Min-Max range  <br><br>
  
3. **Screen for Outliers**  
    + Outliers can distort results. Screen to remove them  <br><br>
    
4. **Calculate Distance**
    + Popular measure of distance between two data point is Euclidean distance
    + Others are Manhattan, Canberra, Asymmetric Binary, Maximum and Minkowski also available  <br><br>
    
5. **Chosoe a Clustering Alrorithm**
    + 

6. **Try few Clustering Solutions**

7. **Visualize the result**
    + Visualization can help you determine the meaning and usefulness of the cluster solution  
    + **Hierarchical** clustering are usually presented as a dendrogram  
    + **Partitioning** results are typically visualized using a bivariate cluster plot  <br><br>

8. **Intepret the Cluster**
    + Once a cluster solution has been obtained, you must interpret (and possibly name) the clusters
    + What do the observations in a cluster have in common? 
    + How do they differ from the observations in other clusters? 
    + This step is typically accomplished by obtaining summary statistics for each variable by cluster
    + For continuous data, the mean or median for each variable within each cluster is calculated. 
    + For mixed data (data that contain categorical variables), the summary statistics will also include modes or category distributions  <br><br>
    
9. **Validate Result**
    + Validating the cluster solution involves asking the question:
        + “Are these groupings in some sense real, and not a manifestation of unique aspects of this dataset or statistical technique?”   
        + If a different cluster method or different sample is employed, would the same clusters be obtained?  
        + The fpc, clv, and clValid packages each contain functions for evaluating the stability of a clustering solution  

## Distance Algorithm

### Euclidean Distance (n dimension)

$$Euclidean-d(p,q) = \sqrt{\sum_{i=1}^n (p_i-q_i)^2} \quad,n = dimension$$  

- The Euclidean distance is a distance measure between two points or or vectors in a two- or multidimensional (Euclidean) space **based on Pythagoras' theorem**   
- The distance is calculated by taking the square root of the sum of the squared pair-wise distances of every dimension  

### Manhattan Distance (n dimension)
$$Manhattan - d(p,q) = \sum_{i=1}^n |p_i-q_i| \quad,n = dimension$$  

- The Manhattan distance (sometimes also called **Taxicab** distance) metric is related to the Euclidean distance
- But instead of calculating the shortest diagonal path ("beeline") between two points, it calculates the distance based on gridlines  


## Clustering Algorithm

### Hierarchical Clustering 

### K-Mean Clustering


