<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Business and Technical Analytics with R</title>
  <meta name="description" content="This is a study and reference notes to solving various business analytics problems using R.">
  <meta name="generator" content="bookdown 0.4 and GitBook 2.6.7">

  <meta property="og:title" content="Business and Technical Analytics with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a study and reference notes to solving various business analytics problems using R." />
  <meta name="github-repo" content="yongks/biz_tech_analytics_r" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Business and Technical Analytics with R" />
  
  <meta name="twitter:description" content="This is a study and reference notes to solving various business analytics problems using R." />
  

<meta name="author" content="Yong Keh Soon">


<meta name="date" content="2017-06-23">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="11-3-comparing-algorithm.html">
<link rel="next" href="11-5-logistic-regression.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Business and Technical Analytics /R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="1-fundamentals.html"><a href="1-fundamentals.html"><i class="fa fa-check"></i><b>1</b> R Fundamentals</a></li>
<li class="chapter" data-level="2" data-path="2-data-generation.html"><a href="2-data-generation.html"><i class="fa fa-check"></i><b>2</b> Data Generation</a></li>
<li class="chapter" data-level="3" data-path="3-data-simulation.html"><a href="3-data-simulation.html"><i class="fa fa-check"></i><b>3</b> Data Simulation</a></li>
<li class="chapter" data-level="4" data-path="4-data-summarization.html"><a href="4-data-summarization.html"><i class="fa fa-check"></i><b>4</b> Data Summarization</a></li>
<li class="chapter" data-level="5" data-path="5-data-preprocessing.html"><a href="5-data-preprocessing.html"><i class="fa fa-check"></i><b>5</b> Data Preprocessing</a></li>
<li class="chapter" data-level="6" data-path="6-find-order-and-filter-data.html"><a href="6-find-order-and-filter-data.html"><i class="fa fa-check"></i><b>6</b> Find, Order and Filter Data</a></li>
<li class="chapter" data-level="7" data-path="7-graphic-visualization.html"><a href="7-graphic-visualization.html"><i class="fa fa-check"></i><b>7</b> Graphic Visualization</a></li>
<li class="chapter" data-level="8" data-path="8-statistics.html"><a href="8-statistics.html"><i class="fa fa-check"></i><b>8</b> Statistics</a></li>
<li class="chapter" data-level="9" data-path="9-clustering-analysis.html"><a href="9-clustering-analysis.html"><i class="fa fa-check"></i><b>9</b> Clustering Analysis</a></li>
<li class="chapter" data-level="10" data-path="10-regression-analysis.html"><a href="10-regression-analysis.html"><i class="fa fa-check"></i><b>10</b> Regression Analysis</a></li>
<li class="chapter" data-level="11" data-path="11-classification.html"><a href="11-classification.html"><i class="fa fa-check"></i><b>11</b> Classification</a><ul>
<li class="chapter" data-level="11.1" data-path="11-1-introduction.html"><a href="11-1-introduction.html"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="11-2-application.html"><a href="11-2-application.html"><i class="fa fa-check"></i><b>11.2</b> Application</a></li>
<li class="chapter" data-level="11.3" data-path="11-3-comparing-algorithm.html"><a href="11-3-comparing-algorithm.html"><i class="fa fa-check"></i><b>11.3</b> Comparing Algorithm</a></li>
<li class="chapter" data-level="11.4" data-path="11-4-performance-measurement.html"><a href="11-4-performance-measurement.html"><i class="fa fa-check"></i><b>11.4</b> Performance Measurement</a><ul>
<li class="chapter" data-level="11.4.1" data-path="11-4-performance-measurement.html"><a href="11-4-performance-measurement.html#confusion-matrix"><i class="fa fa-check"></i><b>11.4.1</b> Confusion Matrix</a></li>
<li class="chapter" data-level="11.4.2" data-path="11-4-performance-measurement.html"><a href="11-4-performance-measurement.html#cutoff-threshold-optimization"><i class="fa fa-check"></i><b>11.4.2</b> Cutoff Threshold Optimization</a></li>
<li class="chapter" data-level="11.4.3" data-path="11-4-performance-measurement.html"><a href="11-4-performance-measurement.html#model-evaluation"><i class="fa fa-check"></i><b>11.4.3</b> Model Evaluation</a></li>
<li class="chapter" data-level="11.4.4" data-path="11-4-performance-measurement.html"><a href="11-4-performance-measurement.html#run-the-code"><i class="fa fa-check"></i><b>11.4.4</b> Run The Code</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="11-5-logistic-regression.html"><a href="11-5-logistic-regression.html"><i class="fa fa-check"></i><b>11.5</b> Logistic Regression</a><ul>
<li class="chapter" data-level="11.5.1" data-path="11-5-logistic-regression.html"><a href="11-5-logistic-regression.html#the-concept"><i class="fa fa-check"></i><b>11.5.1</b> The Concept</a></li>
<li class="chapter" data-level="11.5.2" data-path="11-5-logistic-regression.html"><a href="11-5-logistic-regression.html#assumptions"><i class="fa fa-check"></i><b>11.5.2</b> Assumptions</a></li>
<li class="chapter" data-level="11.5.3" data-path="11-5-logistic-regression.html"><a href="11-5-logistic-regression.html#equations"><i class="fa fa-check"></i><b>11.5.3</b> Equations</a></li>
<li class="chapter" data-level="11.5.4" data-path="11-5-logistic-regression.html"><a href="11-5-logistic-regression.html#sample-data"><i class="fa fa-check"></i><b>11.5.4</b> Sample Data</a></li>
<li class="chapter" data-level="11.5.5" data-path="11-5-logistic-regression.html"><a href="11-5-logistic-regression.html#run-the-code-1"><i class="fa fa-check"></i><b>11.5.5</b> Run The Code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-survival-analysis.html"><a href="12-survival-analysis.html"><i class="fa fa-check"></i><b>12</b> Survival Analysis</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Business and Technical Analytics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="performance-measurement" class="section level2">
<h2><span class="header-section-number">11.4</span> Performance Measurement</h2>
<p>There are many performance measurement used for binary classification. Here are the rules of thumb which one to use:</p>
<ul>
<li><strong>Recall</strong>: If you don’t mind getting some inaccurate result, as long as you get as much correct ones</li>
<li><strong>Precision</strong>: If you demand rate of correctness and willing to reject some correct results<br />
</li>
<li><strong>F1 Score</strong>: For a more balanced measurement, taking into consideraton both recall and precision</li>
</ul>
<div id="confusion-matrix" class="section level3">
<h3><span class="header-section-number">11.4.1</span> Confusion Matrix</h3>
<div class="figure">
<img src="images/confusion_table.jpg" alt="Confusion Matrix and Performance Measurement" />
<p class="caption">Confusion Matrix and Performance Measurement</p>
</div>
<div id="accuracy" class="section level4">
<h4><span class="header-section-number">11.4.1.1</span> Accuracy</h4>
<ul>
<li>Accuracy answers the question: <strong>From the total samples, how many had been correctly predicted by the model ?</strong><br />
</li>
<li><span class="math inline">\(Accuracy = \frac{TP+TN}{TP+TN+FP+FN}\)</span></li>
<li>This measurement is useful when the both <strong>classes are balanced</strong> (that is, the number of TP and TN cases are almost balanced)<br />
</li>
<li>In practice, it seems that the best accuracy is usually achieved when the cutpoint is <strong>near the Probability(actual TRUE)</strong><br />
</li>
<li>Accuracy is completely usessless in highly skewed class. For example, with a disease that only affects 1 in a million people a completely bogus screening test that always reports “negative” will be 99.9999% accurate</li>
</ul>
</div>
<div id="recall" class="section level4">
<h4><span class="header-section-number">11.4.1.2</span> Recall</h4>
<ul>
<li>Recall answers the question: <strong>Out of all actual positive samples, how many were correctly predicted by classifiers ?</strong><br />
</li>
<li><span class="math inline">\(Recall = \frac{TP}{TP+FN}\)</span></li>
</ul>
</div>
<div id="precision" class="section level4">
<h4><span class="header-section-number">11.4.1.3</span> Precision</h4>
<ul>
<li>Precison answers the question: <strong>Out of all the samples classifier predicted as positive, what fraction were correct ?</strong><br />
</li>
<li><span class="math inline">\(Precision = \frac{TP}{TP+FN}\)</span></li>
</ul>
</div>
<div id="f1-score" class="section level4">
<h4><span class="header-section-number">11.4.1.4</span> F1 Score</h4>
<ul>
<li>F1 score is the <strong>harmonic mean of Precision and Recall</strong>. Intuitively, F1 Score is the <strong>weighted average of Precision and Recall</strong>. It takes into account all three measures: TP, FP and FN<br />
</li>
<li><span class="math inline">\(Precision = 2*\frac{Recall * Precision}{Recall + Precision}\)</span><br />
</li>
<li>F1 is usually more useful than accuracy, especially if you have an unbalanced class distribution</li>
</ul>
</div>
<div id="area-under-roc-auroc" class="section level4">
<h4><span class="header-section-number">11.4.1.5</span> Area Under ROC (AUROC)</h4>
<ul>
<li>ROC curve is basically a graph of <strong>TPR vs FPR</strong> (some refer to as Recall vs (1-Sensitivity), plotted for <strong>different thresholds</strong><br />
</li>
<li>Comparing two different models, the model with <strong>higher AUROC is considered to have higher overall Accuracy</strong><br />
</li>
<li>AUROC (Area Under ROC) measures :
<ul>
<li>AUC of <strong>0.5</strong>: means the model is as good as tossing a coin, worthless<br />
</li>
<li>AUC of <strong>1.0</strong>: means for all cutoff points, TPR=1 and FPR=0. Intuitively it means, all samples had been correctly classified into TP (TPR=1) and TN(FPR=0), and there is no FP and FN. Ultiamtely it means Accuracy is 100%</li>
</ul></li>
</ul>
<div class="figure">
<img src="images/roc_curve.gif" alt="AUROC and Thresholds" />
<p class="caption">AUROC and Thresholds</p>
</div>
</div>
</div>
<div id="cutoff-threshold-optimization" class="section level3">
<h3><span class="header-section-number">11.4.2</span> Cutoff Threshold Optimization</h3>
<div id="understanding-cutoff-impacts" class="section level4">
<h4><span class="header-section-number">11.4.2.1</span> Understanding Cutoff Impacts</h4>
<p>Cutoff threshold <strong>direclty influence</strong> the value of TP, FP, TN, FN.<br />
If <strong>cutoff threshold is lowered</strong> (lower probability to classify as Postive), the results are:</p>
<ul>
<li><strong>More linient</strong> and hence <strong>more samples will be classified as Positive</strong><br />
</li>
<li>More predicted Positives means more TP and FP, hence <strong>TPR and FPR increases</strong><br />
</li>
<li>However, <strong>TPR and FPR increases at different rate</strong>:
<ul>
<li>If TPR increases faster than FPR -&gt; this is <strong>good</strong>, as the lowered threshold generated more TP than FP<br />
</li>
<li>If FPR increases faster then TPR -&gt; this is <strong>not good</strong>, as the lowered threhsold generated more FP than TP<br />
</li>
</ul></li>
<li>The cutoff with highest TPR/FPR value is the optimal means optimum point whereby It is possible to discover the optimum cutoff by finding the cutoff with highest TPR/FPR</li>
</ul>
<p>Different threshold produces different performance metrics (Accuracy, Recall, Precision and Specificity and F1-score). As an example, picture below shows how threshold influences the ROC curve.</p>
<div class="figure">
<img src="images/roc_threshold_demo.gif" alt="Threshold and ROC" />
<p class="caption">Threshold and ROC</p>
</div>
<p>The only way to estimate the <strong>optimum threshold</strong> for each of the performance measurement will be to measure them for a <strong>wide range of threshold</strong>.</p>
</div>
<div id="cutoff-impact-visualization" class="section level4">
<h4><span class="header-section-number">11.4.2.2</span> Cutoff Impact Visualization</h4>
<p>Selecting a cutoff threshold depends on the objectives of the researcher. To help understanding the how cutoff changes the performance metircs, try <strong>visualize</strong> them in below graph:</p>
<p>1.Threshold vs Accuracy<br />
2.Threshold vs Recall (TPR)<br />
3.Threshold vs TPR/FPR<br />
4.Threshold vs Precision<br />
5.Threshold vs F1 Score<br />
6.ROC Curve (TPR vs FPR)</p>
</div>
</div>
<div id="model-evaluation" class="section level3">
<h3><span class="header-section-number">11.4.3</span> Model Evaluation</h3>
<div id="compare-with-baseline" class="section level4">
<h4><span class="header-section-number">11.4.3.1</span> Compare With Baseline</h4>
<p>In an highly unbalanced dataset (eg. patients that is diagnosed with cancer skewed towards negative). Hence, it is essential to make a <strong>lazy baseline comparison</strong> with simply classifying every records with negative (cutoff at 1) or positive (cutoff at 0).</p>
<p>Put in mind of the dataset used for comparison:</p>
<ul>
<li>Use data from training set as model baseline, when concerning training performance<br />
</li>
<li>Use dta from test set as model baseline, when concerning test performance</li>
</ul>
<p><strong>Model Accuracy is not better than ‘lazy’ baseline !</strong></p>
<ul>
<li>In highly bias class, in term of accuracy, the model usually unable to outperform the baseline by good marign<br />
</li>
<li>Hence <strong>accuracy</strong> is not a good measurement in such case<br />
</li>
<li>Model is still useful if the research objective is towards other measurement usch as <strong>recall, precision</strong><br />
</li>
<li>Adjust the threshold to achieve optimum better objectives</li>
</ul>
</div>
<div id="combination-of-variables" class="section level4">
<h4><span class="header-section-number">11.4.3.2</span> Combination of Variables</h4>
<p>Model AIC to measure the usefullness. It is like R-square in linear regression. Use it to compare model with different combinations of variables.</p>
<p>Since logistic regression is a actual <strong>linear regression of ln(odds)</strong>, <strong>multicolinearity</strong> rule apply.</p>
</div>
</div>
<div id="run-the-code" class="section level3">
<h3><span class="header-section-number">11.4.4</span> Run The Code</h3>
<div id="measurement-function" class="section level4">
<h4><span class="header-section-number">11.4.4.1</span> Measurement Function</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">#######################################################################################
#### Function Return Various Performance by Cutoff Threshold
##### Input : fit: glm model object that uses probability classifier
#######################################################################################
eval.binclass =<span class="st"> </span><span class="cf">function</span>(<span class="dt">fit =</span> <span class="ot">NULL</span>, <span class="dt">cutoff.min =</span> <span class="dv">0</span>, <span class="dt">cutoff.max =</span> <span class="dv">1</span>, <span class="dt">cutoff.by =</span> <span class="fl">0.1</span>) {

    ## Calculate Key Measurements For One Cutoff
    calc.metrics =<span class="st"> </span><span class="cf">function</span>(x) {
        actual =<span class="st"> </span><span class="kw">factor</span>(<span class="kw">as.logical</span>(fit<span class="op">$</span>model[[<span class="dv">1</span>]]), <span class="dt">levels =</span> <span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">FALSE</span>))
        predicted =<span class="st"> </span><span class="kw">factor</span>(fit<span class="op">$</span>fitted.values <span class="op">&gt;</span><span class="st"> </span>x, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">FALSE</span>))
        ct =<span class="st"> </span><span class="kw">table</span>(actual, predicted, <span class="dt">useNA =</span> <span class="st">&#39;no&#39;</span>, <span class="dt">exclude =</span> <span class="kw">c</span>(<span class="ot">NA</span>)) <span class="co">#confusion table</span>
        accuracy =<span class="st"> </span>(ct[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>ct[<span class="dv">4</span>]) <span class="op">/</span><span class="st"> </span>(<span class="kw">sum</span>(ct))
        recall =<span class="st"> </span>ct[<span class="dv">1</span>] <span class="op">/</span><span class="st"> </span>(ct[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>ct[<span class="dv">3</span>])
        precision =<span class="st"> </span>ct[<span class="dv">1</span>] <span class="op">/</span><span class="st"> </span>(ct[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>ct[<span class="dv">2</span>])
        specificity =<span class="st"> </span>ct[<span class="dv">4</span>] <span class="op">/</span><span class="st"> </span>(ct[<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>ct[<span class="dv">4</span>])
        <span class="kw">data.frame</span>(<span class="dt">cutoff =</span> x, <span class="dt">accuracy =</span> accuracy, <span class="dt">recall =</span> recall, <span class="dt">precision =</span> precision,
            <span class="dt">specificity =</span> specificity, <span class="dt">fscore =</span> <span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(precision <span class="op">*</span><span class="st"> </span>recall <span class="op">/</span><span class="st"> </span>(precision <span class="op">+</span><span class="st"> </span>recall)), <span class="dt">fpr =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>specificity,
            <span class="dt">tpr_fpr =</span> recall <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>specificity), <span class="dt">tp =</span> ct[<span class="dv">1</span>], <span class="dt">fp =</span> ct[<span class="dv">2</span>], <span class="dt">fn=</span>ct[<span class="dv">3</span>], <span class="dt">tn=</span>ct[<span class="dv">4</span>])
    }

    ## Derive cutoff breakpoints, and loop to calculate measures for each breakpoint
    cutoffs =<span class="st"> </span><span class="kw">seq</span>(cutoff.min, cutoff.max, <span class="dt">by =</span> cutoff.by)
    perf.tab =<span class="st"> </span><span class="kw">do.call</span>(rbind, <span class="kw">lapply</span>(cutoffs, <span class="dt">FUN =</span> calc.metrics))

    ## Calculate AUC
    h =<span class="st"> </span>(perf.tab<span class="op">$</span>recall[<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>perf.tab<span class="op">$</span>recall[<span class="op">-</span><span class="kw">length</span>(perf.tab<span class="op">$</span>recall)]) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>
    w =<span class="st"> </span><span class="kw">abs</span>(<span class="kw">diff</span>(perf.tab<span class="op">$</span>fpr))
    auc =<span class="st"> </span><span class="kw">sum</span>(h<span class="op">*</span>w)

    ## Summarize optimal cutoff for max performance on various metrics
    best.metrics =<span class="st"> </span><span class="kw">rbind</span>(
        <span class="dt">best.accuracy =</span> <span class="kw">c</span>(<span class="dt">max =</span> <span class="kw">max</span>(perf.tab<span class="op">$</span>accuracy, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),   <span class="dt">cutoff =</span> perf.tab<span class="op">$</span>cutoff[<span class="kw">which.max</span>(perf.tab<span class="op">$</span>accuracy)]),
        <span class="dt">best.precision =</span> <span class="kw">c</span>(<span class="dt">max =</span> <span class="kw">max</span>(perf.tab<span class="op">$</span>precision, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>), <span class="dt">cutoff =</span> perf.tab<span class="op">$</span>cutoff[<span class="kw">which.max</span>(perf.tab<span class="op">$</span>precision)]),
        <span class="dt">best.recall =</span> <span class="kw">c</span>(<span class="dt">max =</span> <span class="kw">max</span>(perf.tab<span class="op">$</span>recall, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),       <span class="dt">cutoff =</span> perf.tab<span class="op">$</span>cutoff[<span class="kw">which.max</span>(perf.tab<span class="op">$</span>recall)]),
        <span class="dt">best.fscore =</span> <span class="kw">c</span>(<span class="dt">max =</span> <span class="kw">max</span>(perf.tab<span class="op">$</span>fscore, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),       <span class="dt">cutoff =</span> perf.tab<span class="op">$</span>cutoff[<span class="kw">which.max</span>(perf.tab<span class="op">$</span>fscore)])
    )

    ## Plot ROC graphs
    <span class="kw">plot</span>(perf.tab<span class="op">$</span>fpr, perf.tab<span class="op">$</span>recall, <span class="dt">type =</span> <span class="st">&#39;b&#39;</span>, <span class="dt">main =</span> <span class="kw">paste</span>(<span class="st">&#39;ROC Curve, auc=&#39;</span>,auc),
        <span class="dt">xlab=</span><span class="st">&#39;False Positive Rate, or (1-Specificity)&#39;</span>, <span class="dt">ylab=</span><span class="st">&#39;Recall or True Positive Rate&#39;</span>)
    <span class="kw">grid</span>()
    <span class="kw">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)

    ## Plot Accuracy graph
    <span class="kw">plot</span>(perf.tab<span class="op">$</span>cutoff, perf.tab<span class="op">$</span>accuracy, <span class="dt">type =</span> <span class="st">&#39;b&#39;</span>, <span class="dt">main =</span> <span class="st">&#39;Accuracy over Cutoffs&#39;</span>,
        <span class="dt">xlab =</span> <span class="st">&#39;Cutoff Thresholds&#39;</span>, <span class="dt">ylab =</span> <span class="st">&#39;Accuracy&#39;</span>)
    <span class="kw">grid</span>()
    <span class="kw">text</span>(best.metrics[<span class="st">&#39;best.accuracy&#39;</span>, <span class="st">&#39;cutoff&#39;</span>], <span class="kw">min</span>(perf.tab<span class="op">$</span>accuracy, <span class="dt">na.rm =</span> T) <span class="op">+</span><span class="st"> </span><span class="kw">diff</span>(<span class="kw">range</span>(perf.tab<span class="op">$</span>accuracy, <span class="dt">na.rm =</span> T)) <span class="op">/</span><span class="st"> </span><span class="dv">10</span>, best.metrics[<span class="st">&#39;best.accuracy&#39;</span>, <span class="st">&#39;cutoff&#39;</span>], <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)
    <span class="kw">abline</span>(<span class="dt">v =</span> best.metrics[<span class="st">&#39;best.accuracy&#39;</span>, <span class="st">&#39;cutoff&#39;</span>], <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
    <span class="kw">abline</span>(<span class="dt">h =</span> best.metrics[<span class="st">&#39;best.accuracy&#39;</span>, <span class="st">&#39;max&#39;</span>], <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)

    ## Plot Precision graph
    <span class="kw">plot</span>(perf.tab<span class="op">$</span>cutoff, perf.tab<span class="op">$</span>precision, <span class="dt">type =</span> <span class="st">&#39;b&#39;</span>, <span class="dt">main =</span> <span class="st">&#39;Precision over Cutoffs&#39;</span>,
        <span class="dt">xlab =</span> <span class="st">&#39;Cutoff Thresholds&#39;</span>, <span class="dt">ylab =</span> <span class="st">&#39;Precision&#39;</span>)
    <span class="kw">grid</span>()
    <span class="kw">text</span>(best.metrics[<span class="st">&#39;best.precision&#39;</span>, <span class="st">&#39;cutoff&#39;</span>], <span class="kw">min</span>(perf.tab<span class="op">$</span>precision,<span class="dt">na.rm =</span> T)<span class="op">+</span><span class="kw">diff</span>(<span class="kw">range</span>(perf.tab<span class="op">$</span>precision, <span class="dt">na.rm=</span>T))<span class="op">/</span><span class="dv">10</span>, best.metrics[<span class="st">&#39;best.precision&#39;</span>, <span class="st">&#39;cutoff&#39;</span>], <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)
    <span class="kw">abline</span>(<span class="dt">v =</span> best.metrics[<span class="st">&#39;best.precision&#39;</span>, <span class="st">&#39;cutoff&#39;</span>], <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
    <span class="kw">abline</span>(<span class="dt">h =</span> best.metrics[<span class="st">&#39;best.precision&#39;</span>, <span class="st">&#39;max&#39;</span>], <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)

    ## Plot F1 Scoregraph
    <span class="kw">plot</span>(perf.tab<span class="op">$</span>cutoff, perf.tab<span class="op">$</span>fscore, <span class="dt">type =</span> <span class="st">&#39;b&#39;</span>, <span class="dt">main =</span> <span class="st">&#39;F1-Score over Cutoffs&#39;</span>,
        <span class="dt">xlab =</span> <span class="st">&#39;Cutoff Thresholds&#39;</span>, <span class="dt">ylab =</span> <span class="st">&#39;F1-Score&#39;</span>)
    <span class="kw">grid</span>()
    <span class="kw">text</span>(best.metrics[<span class="st">&#39;best.fscore&#39;</span>, <span class="st">&#39;cutoff&#39;</span>], <span class="kw">min</span>(perf.tab<span class="op">$</span>fscore, <span class="dt">na.rm =</span> T) <span class="op">+</span><span class="st"> </span><span class="kw">diff</span>(<span class="kw">range</span>(perf.tab<span class="op">$</span>fscore, <span class="dt">na.rm =</span> T)) <span class="op">/</span><span class="st"> </span><span class="dv">10</span>, best.metrics[<span class="st">&#39;best.fscore&#39;</span>, <span class="st">&#39;cutoff&#39;</span>], <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)
    <span class="kw">abline</span>(<span class="dt">v =</span> best.metrics[<span class="st">&#39;best.fscore&#39;</span>, <span class="st">&#39;cutoff&#39;</span>], <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
    <span class="kw">abline</span>(<span class="dt">h =</span> best.metrics[<span class="st">&#39;best.fscore&#39;</span>, <span class="st">&#39;max&#39;</span>], <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)

    <span class="co"># return performance table, and optimal values per metric</span>
    <span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">perf.tab =</span> perf.tab, <span class="dt">auroc =</span> auc, <span class="dt">best.metrics =</span> best.metrics))
}</code></pre></div>
</div>
<div id="train-the-model" class="section level4">
<h4><span class="header-section-number">11.4.4.2</span> Train The Model</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">### Load The Data and Build The Model
train.data =<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;./datasets/hr.train.csv&#39;</span>)

<span class="kw">str</span>(train.data)
## &#39;data.frame&#39;:    12000 obs. of  7 variables:
##  $ S      : num  0.38 0.8 0.11 0.72 0.37 0.41 0.1 0.92 0.89 0.42 ...
##  $ LPE    : num  0.53 0.86 0.88 0.87 0.52 0.5 0.77 0.85 1 0.53 ...
##  $ NP     : int  2 5 7 5 2 2 6 5 5 2 ...
##  $ ANH    : int  157 262 272 223 159 153 247 259 224 142 ...
##  $ TIC    : int  3 6 4 5 3 3 4 5 5 3 ...
##  $ Newborn: int  0 0 0 0 0 0 0 0 0 0 ...
##  $ left   : int  1 1 1 1 1 1 1 1 1 1 ...

## Trian The Model Using Logistic Regression
my.fit =<span class="st"> </span><span class="kw">glm</span>(left <span class="op">~</span><span class="st"> </span>., <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> train.data)</code></pre></div>
</div>
<div id="run-the-performance-eval-function" class="section level4">
<h4><span class="header-section-number">11.4.4.3</span> Run the Performance Eval Function</h4>
<p><strong>List The Performance Table</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
r =<span class="st"> </span><span class="kw">eval.binclass</span>(my.fit, <span class="dt">cutoff.by =</span> <span class="fl">0.1</span>)

<span class="kw">kable</span>(r<span class="op">$</span>perf.tab)</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">cutoff</th>
<th align="right">accuracy</th>
<th align="right">recall</th>
<th align="right">precision</th>
<th align="right">specificity</th>
<th align="right">fscore</th>
<th align="right">fpr</th>
<th align="right">tpr_fpr</th>
<th align="right">tp</th>
<th align="right">fp</th>
<th align="right">fn</th>
<th align="right">tn</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.0</td>
<td align="right">0.1666667</td>
<td align="right">1.0000</td>
<td align="right">0.1666667</td>
<td align="right">0.0000</td>
<td align="right">0.2857143</td>
<td align="right">1.0000</td>
<td align="right">1.0000000</td>
<td align="right">2000</td>
<td align="right">10000</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">0.1</td>
<td align="right">0.6498333</td>
<td align="right">0.9505</td>
<td align="right">0.3166223</td>
<td align="right">0.5897</td>
<td align="right">0.4750125</td>
<td align="right">0.4103</td>
<td align="right">2.3165976</td>
<td align="right">1901</td>
<td align="right">4103</td>
<td align="right">99</td>
<td align="right">5897</td>
</tr>
<tr class="odd">
<td align="right">0.2</td>
<td align="right">0.8126667</td>
<td align="right">0.8025</td>
<td align="right">0.4641411</td>
<td align="right">0.8147</td>
<td align="right">0.5881275</td>
<td align="right">0.1853</td>
<td align="right">4.3308149</td>
<td align="right">1605</td>
<td align="right">1853</td>
<td align="right">395</td>
<td align="right">8147</td>
</tr>
<tr class="even">
<td align="right">0.3</td>
<td align="right">0.8195000</td>
<td align="right">0.4730</td>
<td align="right">0.4596696</td>
<td align="right">0.8888</td>
<td align="right">0.4662395</td>
<td align="right">0.1112</td>
<td align="right">4.2535971</td>
<td align="right">946</td>
<td align="right">1112</td>
<td align="right">1054</td>
<td align="right">8888</td>
</tr>
<tr class="odd">
<td align="right">0.4</td>
<td align="right">0.8129167</td>
<td align="right">0.2610</td>
<td align="right">0.4049651</td>
<td align="right">0.9233</td>
<td align="right">0.3174217</td>
<td align="right">0.0767</td>
<td align="right">3.4028683</td>
<td align="right">522</td>
<td align="right">767</td>
<td align="right">1478</td>
<td align="right">9233</td>
</tr>
<tr class="even">
<td align="right">0.5</td>
<td align="right">0.8204167</td>
<td align="right">0.1905</td>
<td align="right">0.4154853</td>
<td align="right">0.9464</td>
<td align="right">0.2612273</td>
<td align="right">0.0536</td>
<td align="right">3.5541045</td>
<td align="right">381</td>
<td align="right">536</td>
<td align="right">1619</td>
<td align="right">9464</td>
</tr>
<tr class="odd">
<td align="right">0.6</td>
<td align="right">0.8105000</td>
<td align="right">0.0385</td>
<td align="right">0.1799065</td>
<td align="right">0.9649</td>
<td align="right">0.0634267</td>
<td align="right">0.0351</td>
<td align="right">1.0968661</td>
<td align="right">77</td>
<td align="right">351</td>
<td align="right">1923</td>
<td align="right">9649</td>
</tr>
<tr class="even">
<td align="right">0.7</td>
<td align="right">0.8190833</td>
<td align="right">0.0120</td>
<td align="right">0.1095890</td>
<td align="right">0.9805</td>
<td align="right">0.0216314</td>
<td align="right">0.0195</td>
<td align="right">0.6153846</td>
<td align="right">24</td>
<td align="right">195</td>
<td align="right">1976</td>
<td align="right">9805</td>
</tr>
<tr class="odd">
<td align="right">0.8</td>
<td align="right">0.8280833</td>
<td align="right">0.0000</td>
<td align="right">0.0000000</td>
<td align="right">0.9937</td>
<td align="right">NaN</td>
<td align="right">0.0063</td>
<td align="right">0.0000000</td>
<td align="right">0</td>
<td align="right">63</td>
<td align="right">2000</td>
<td align="right">9937</td>
</tr>
<tr class="even">
<td align="right">0.9</td>
<td align="right">0.8331667</td>
<td align="right">0.0000</td>
<td align="right">0.0000000</td>
<td align="right">0.9998</td>
<td align="right">NaN</td>
<td align="right">0.0002</td>
<td align="right">0.0000000</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">2000</td>
<td align="right">9998</td>
</tr>
<tr class="odd">
<td align="right">1.0</td>
<td align="right">0.8333333</td>
<td align="right">0.0000</td>
<td align="right">NaN</td>
<td align="right">1.0000</td>
<td align="right">NaN</td>
<td align="right">0.0000</td>
<td align="right">NaN</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">2000</td>
<td align="right">10000</td>
</tr>
</tbody>
</table>
<p><img src="biz_tech_analytics_r_files/figure-html/unnamed-chunk-3-1.png" width="864" /></p>
<p><strong>AUROC</strong><br />
<strong><code>$auroc</code></strong> is the <strong>area under ROC</strong>, calculated for each simulated threshold.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r<span class="op">$</span>auroc
## [1] 0.8400424</code></pre></div>
<p><strong>Summary Best Metrics</strong><br />
<strong><code>$best.metrics</code></strong> provides <strong>optimal threshold</strong> that maximize individual metrics, based on the simulated thresholds.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r<span class="op">$</span>best.metrics
##                      max cutoff
## best.accuracy  0.8333333    1.0
## best.precision 0.4641411    0.2
## best.recall    1.0000000    0.0
## best.fscore    0.5881275    0.2</code></pre></div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="11-3-comparing-algorithm.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="11-5-logistic-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/yongks/biz_tech_analytics_r/edit/master/11-classification.Rmd",
"text": "Edit"
},
"download": ["biz_tech_analytics_r.pdf", "biz_tech_analytics_r.epub", "biz_tech_analytics_r.mobi"],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
